{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/celesdeh/.local/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: nltk in /home/celesdeh/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in /home/celesdeh/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: seaborn in /home/celesdeh/.local/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: wordcloud in /home/celesdeh/.local/lib/python3.10/site-packages (1.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/celesdeh/.local/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/celesdeh/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/celesdeh/.local/lib/python3.10/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/celesdeh/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/lib/python3/dist-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/celesdeh/.local/lib/python3.10/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/celesdeh/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/celesdeh/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/celesdeh/.local/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /home/celesdeh/.local/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib nltk pandas seaborn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>descricao</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O Hobbit - 7ª Ed. 2013</td>\n",
       "      <td>Produto NovoBilbo Bolseiro é um hobbit que lev...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Livro - It A Coisa - Stephen King</td>\n",
       "      <td>Produto NovoDurante as férias escolares de 195...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Box  As Crônicas De Gelo E Fogo  Pocket  5 Li...</td>\n",
       "      <td>Produto NovoTodo o reino de Westeros ao alcanc...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Box Harry Potter</td>\n",
       "      <td>Produto Novo e Físico  A série Harry Potter ch...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Livro Origem - Dan Brown</td>\n",
       "      <td>Produto NovoDe Onde Viemos? Para Onde Vamos? R...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                nome  \\\n",
       "0                            O Hobbit - 7ª Ed. 2013    \n",
       "1                 Livro - It A Coisa - Stephen King    \n",
       "2   Box  As Crônicas De Gelo E Fogo  Pocket  5 Li...   \n",
       "3                                  Box Harry Potter    \n",
       "4                          Livro Origem - Dan Brown    \n",
       "\n",
       "                                           descricao categoria  \n",
       "0  Produto NovoBilbo Bolseiro é um hobbit que lev...     livro  \n",
       "1  Produto NovoDurante as férias escolares de 195...     livro  \n",
       "2  Produto NovoTodo o reino de Westeros ao alcanc...     livro  \n",
       "3  Produto Novo e Físico  A série Harry Potter ch...     livro  \n",
       "4  Produto NovoDe Onde Viemos? Para Onde Vamos? R...     livro  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_data = pd.read_csv('produtos.csv', delimiter=';')\n",
    "products_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns dados da coluna 'descrição' estão faltando, e todas as outras colunas não possuem valores nulos. Todos os dados são strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4080 entries, 0 to 4079\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   nome       4080 non-null   object\n",
      " 1   descricao  2916 non-null   object\n",
      " 2   categoria  4080 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 95.8+ KB\n"
     ]
    }
   ],
   "source": [
    "products_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O target aqui é a categoria, e todas as 4 classes estão balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoria\n",
      "brinquedo    1020\n",
      "game         1020\n",
      "livro        1020\n",
      "maquiagem    1020\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(products_data.groupby('categoria').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processamento para concatenação do nome do produto e descrição\n",
    "\n",
    "eliminação das colunas de nome e descricao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_data = products_data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informacao</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>produto novobilbo bolseiro é um hobbit que lev...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>produto novodurante as férias escolares de 195...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>produto novotodo o reino de westeros ao alcanc...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>produto novo e físico  a série harry potter ch...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>produto novode onde viemos? para onde vamos? r...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          informacao target\n",
       "0  produto novobilbo bolseiro é um hobbit que lev...  livro\n",
       "1  produto novodurante as férias escolares de 195...  livro\n",
       "2  produto novotodo o reino de westeros ao alcanc...  livro\n",
       "3  produto novo e físico  a série harry potter ch...  livro\n",
       "4  produto novode onde viemos? para onde vamos? r...  livro"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenando as colunas nome e descricao\n",
    "\n",
    "df = pd.DataFrame(columns=[\"informacao\",\"target\"])\n",
    "products_data[\"informacao\"] = products_data[['descricao', 'nome']].agg('-'.join, axis=1)\n",
    "df[\"informacao\"] = products_data[\"informacao\"]\n",
    "df[\"target\"] = products_data[\"categoria\"]\n",
    "df[\"informacao\"]=df[\"informacao\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords(df, text_column):\n",
    "    \"\"\"\n",
    "    Function to remove stop words from a DataFrame column containing text data.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame containing the text data.\n",
    "        text_column (str): The name of the column in the DataFrame containing the text data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with the stop words removed.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    # Define a function to remove stop words from a sentence\n",
    "    def remove_stopwords_from_sentence(sentence):\n",
    "        words = word_tokenize(sentence)\n",
    "        filtered_sentence = [word for word in words if word.lower() not in stop_words]\n",
    "        return ' '.join(filtered_sentence)\n",
    "\n",
    "    # Apply the function to the specified text column\n",
    "    df['cleaned_text'] = df[text_column].apply(remove_stopwords_from_sentence)\n",
    "\n",
    "    return df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = remove_stopwords(df, 'informacao')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informacao</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>produto novobilbo bolseiro é um hobbit que lev...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novobilbo bolseiro hobbit leva vida co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>produto novodurante as férias escolares de 195...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novodurante férias escolares 1958 , de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>produto novotodo o reino de westeros ao alcanc...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novotodo reino westeros alcance mãos s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>produto novo e físico  a série harry potter ch...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novo físico série harry potter chega p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>produto novode onde viemos? para onde vamos? r...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novode onde viemos ? onde vamos ? robe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          informacao target  \\\n",
       "0  produto novobilbo bolseiro é um hobbit que lev...  livro   \n",
       "1  produto novodurante as férias escolares de 195...  livro   \n",
       "2  produto novotodo o reino de westeros ao alcanc...  livro   \n",
       "3  produto novo e físico  a série harry potter ch...  livro   \n",
       "4  produto novode onde viemos? para onde vamos? r...  livro   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  produto novobilbo bolseiro hobbit leva vida co...  \n",
       "1  produto novodurante férias escolares 1958 , de...  \n",
       "2  produto novotodo reino westeros alcance mãos s...  \n",
       "3  produto novo físico série harry potter chega p...  \n",
       "4  produto novode onde viemos ? onde vamos ? robe...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=df['target'],label=\"Count\") \n",
    "plt.show() # plota o gráfico por categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud (corrigir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "def create_wordcloud(df, text_column, color=\"blue\"):\n",
    "    print(text_column)\n",
    "    text = \" \".join(df[text_column].astype(str))\n",
    "    word_cloud = WordCloud(\n",
    "        width=3000,\n",
    "        height=2000,\n",
    "        random_state=1,\n",
    "        background_color=color,\n",
    "        collocations=False\n",
    "    ).generate(text)\n",
    "\n",
    "    return word_cloud.to_array()  # Convert WordCloud object to a NumPy array (image)\n",
    "\n",
    "word_cloud_image = create_wordcloud(df_cleaned,\"cleaned_text\")\n",
    "\n",
    "Plot the word cloud image on the appropriate subplot\n",
    "\n",
    "plt.imshow(word_cloud_image, interpolation='bilinear')\n",
    "plt.title('Word Cloud do sentimento neutro sem os nomes dos candidatos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo separação das palavras e removendo pontuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [produto, novobilbo, bolseiro, hobbit, leva, v...\n",
      "1    [produto, novodurante, férias, escolares, 1958...\n",
      "2    [produto, novotodo, reino, westeros, alcance, ...\n",
      "3    [produto, novo, físico, série, harry, potter, ...\n",
      "4    [produto, novode, onde, viemos, onde, vamos, r...\n",
      "Name: tokens, dtype: object\n",
      "0    {'produto': 1, 'novobilbo': 1, 'bolseiro': 1, ...\n",
      "1    {'produto': 1, 'novodurante': 1, 'férias': 1, ...\n",
      "2    {'produto': 1, 'novotodo': 1, 'reino': 1, 'wes...\n",
      "3    {'produto': 2, 'novo': 1, 'físico': 1, 'série'...\n",
      "4    {'produto': 1, 'novode': 1, 'onde': 2, 'viemos...\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "df_cleaned['tokens'] = df_cleaned['cleaned_text'].apply(tokenizer.tokenize) # aplica o regex tokenizer\n",
    "print(df_cleaned['tokens'].head())\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = df_cleaned['tokens'].apply(FreqDist) # calcula a frequência de cada token\n",
    "print(fdist.head()) # frequencia na coluna sem stop_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A impressão acima mostra a frequência das palavras após tratamentos para lowercase e sem stopwords. Abaixo segue as listas sem tratamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'Produto': 1, 'NovoBilbo': 1, 'Bolseiro': 1, ...\n",
      "1    {'Produto': 1, 'NovoDurante': 1, 'as': 1, 'fér...\n",
      "2    {'Produto': 1, 'NovoTodo': 1, 'o': 1, 'reino':...\n",
      "3    {'Produto': 2, 'Novo': 1, 'e': 33, 'Físico': 1...\n",
      "4    {'Produto': 1, 'NovoDe': 1, 'Onde': 2, 'Viemos...\n",
      "Name: informacao, dtype: object\n"
     ]
    }
   ],
   "source": [
    "fdist_comstop = products_data['informacao'].apply(tokenizer.tokenize).apply(FreqDist)\n",
    "print(fdist_comstop.head()) # Frequencia na coluna com stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informacao</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>produto novobilbo bolseiro é um hobbit que lev...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novobilbo bolseiro hobbit leva vida co...</td>\n",
       "      <td>[produto, novobilbo, bolseiro, hobbit, leva, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>produto novodurante as férias escolares de 195...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novodurante férias escolares 1958 , de...</td>\n",
       "      <td>[produto, novodurante, férias, escolares, 1958...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>produto novotodo o reino de westeros ao alcanc...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novotodo reino westeros alcance mãos s...</td>\n",
       "      <td>[produto, novotodo, reino, westeros, alcance, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>produto novo e físico  a série harry potter ch...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novo físico série harry potter chega p...</td>\n",
       "      <td>[produto, novo, físico, série, harry, potter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>produto novode onde viemos? para onde vamos? r...</td>\n",
       "      <td>livro</td>\n",
       "      <td>produto novode onde viemos ? onde vamos ? robe...</td>\n",
       "      <td>[produto, novode, onde, viemos, onde, vamos, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          informacao target  \\\n",
       "0  produto novobilbo bolseiro é um hobbit que lev...  livro   \n",
       "1  produto novodurante as férias escolares de 195...  livro   \n",
       "2  produto novotodo o reino de westeros ao alcanc...  livro   \n",
       "3  produto novo e físico  a série harry potter ch...  livro   \n",
       "4  produto novode onde viemos? para onde vamos? r...  livro   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  produto novobilbo bolseiro hobbit leva vida co...   \n",
       "1  produto novodurante férias escolares 1958 , de...   \n",
       "2  produto novotodo reino westeros alcance mãos s...   \n",
       "3  produto novo físico série harry potter chega p...   \n",
       "4  produto novode onde viemos ? onde vamos ? robe...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [produto, novobilbo, bolseiro, hobbit, leva, v...  \n",
       "1  [produto, novodurante, férias, escolares, 1958...  \n",
       "2  [produto, novotodo, reino, westeros, alcance, ...  \n",
       "3  [produto, novo, físico, série, harry, potter, ...  \n",
       "4  [produto, novode, onde, viemos, onde, vamos, r...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemmer.\n",
    "Extrai o sufixo das palavras, usado para facilitar a associação entre palavras com sentidos próximos.\n",
    "\n",
    "\n",
    "Precisão razoável.\n",
    "\n",
    "\n",
    "Por exemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "livr\n",
      "livreir\n",
      "livr\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"livro\"))\n",
    "print(stemmer.stem(\"livreiro\"))\n",
    "print(stemmer.stem(\"livraria\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['stemmed'] = df_cleaned['tokens'].apply(lambda x: [stemmer.stem(y) for y in x]) # Aplica o stemmer pra cada palavra\n",
    "df_processed = df_cleaned.drop(columns=[\"tokens\",\"informacao\"]) # Exclui a coluna sem o stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novobilbo bolseiro hobbit leva vida co...</td>\n",
       "      <td>[produt, novobilb, bolseir, hobbit, lev, vid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novodurante férias escolares 1958 , de...</td>\n",
       "      <td>[produt, novodur, fér, escol, 1958, derry, pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novotodo reino westeros alcance mãos s...</td>\n",
       "      <td>[produt, novotod, rein, wester, alcanc, mã, sé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novo físico série harry potter chega p...</td>\n",
       "      <td>[produt, nov, físic, séri, harry, pott, cheg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novode onde viemos ? onde vamos ? robe...</td>\n",
       "      <td>[produt, novod, onde, viem, onde, vam, robert,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                       cleaned_text  \\\n",
       "0  livro  produto novobilbo bolseiro hobbit leva vida co...   \n",
       "1  livro  produto novodurante férias escolares 1958 , de...   \n",
       "2  livro  produto novotodo reino westeros alcance mãos s...   \n",
       "3  livro  produto novo físico série harry potter chega p...   \n",
       "4  livro  produto novode onde viemos ? onde vamos ? robe...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [produt, novobilb, bolseir, hobbit, lev, vid, ...  \n",
       "1  [produt, novodur, fér, escol, 1958, derry, pac...  \n",
       "2  [produt, novotod, rein, wester, alcanc, mã, sé...  \n",
       "3  [produt, nov, físic, séri, harry, pott, cheg, ...  \n",
       "4  [produt, novod, onde, viem, onde, vam, robert,...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head() # Mostra o dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### passo opcional para converter tokens em inteiros: \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X['stemmed'] = X['stemmed'].apply(lambda col: le.fit_transform(col)) # transforma as palavras em inteiros\n",
    "print(X['stemmed'].head(10))\n",
    "\n",
    "y = le.fit_transform(y) # transforma cada categoria em um inteiro\n",
    "\n",
    "\n",
    "fdist = X['stemmed'].apply(FreqDist) # calcula a frequência de cada token\n",
    "print(fdist.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Une os tokens em uma única string novamente para ser usada com FeatureExtraction\n",
    "\n",
    "#df_processed[\"strings\"]= df_processed[\"stemmed\"].str.join(\" \") # reunindo cada elemento da lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>strings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novobilbo bolseiro hobbit leva vida co...</td>\n",
       "      <td>[produt, novobilb, bolseir, hobbit, lev, vid, ...</td>\n",
       "      <td>produt novobilb bolseir hobbit lev vid confort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novodurante férias escolares 1958 , de...</td>\n",
       "      <td>[produt, novodur, fér, escol, 1958, derry, pac...</td>\n",
       "      <td>produt novodur fér escol 1958 derry pacat cida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novotodo reino westeros alcance mãos s...</td>\n",
       "      <td>[produt, novotod, rein, wester, alcanc, mã, sé...</td>\n",
       "      <td>produt novotod rein wester alcanc mã séri crôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novo físico série harry potter chega p...</td>\n",
       "      <td>[produt, nov, físic, séri, harry, pott, cheg, ...</td>\n",
       "      <td>produt nov físic séri harry pott cheg pratelei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>livro</td>\n",
       "      <td>produto novode onde viemos ? onde vamos ? robe...</td>\n",
       "      <td>[produt, novod, onde, viem, onde, vam, robert,...</td>\n",
       "      <td>produt novod onde viem onde vam robert langdon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                       cleaned_text  \\\n",
       "0  livro  produto novobilbo bolseiro hobbit leva vida co...   \n",
       "1  livro  produto novodurante férias escolares 1958 , de...   \n",
       "2  livro  produto novotodo reino westeros alcance mãos s...   \n",
       "3  livro  produto novo físico série harry potter chega p...   \n",
       "4  livro  produto novode onde viemos ? onde vamos ? robe...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [produt, novobilb, bolseir, hobbit, lev, vid, ...   \n",
       "1  [produt, novodur, fér, escol, 1958, derry, pac...   \n",
       "2  [produt, novotod, rein, wester, alcanc, mã, sé...   \n",
       "3  [produt, nov, físic, séri, harry, pott, cheg, ...   \n",
       "4  [produt, novod, onde, viem, onde, vam, robert,...   \n",
       "\n",
       "                                             strings  \n",
       "0  produt novobilb bolseir hobbit lev vid confort...  \n",
       "1  produt novodur fér escol 1958 derry pacat cida...  \n",
       "2  produt novotod rein wester alcanc mã séri crôn...  \n",
       "3  produt nov físic séri harry pott cheg pratelei...  \n",
       "4  produt novod onde viem onde vam robert langdon...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[\"strings\"]= df_processed[\"stemmed\"].str.join(\" \") # reunindo cada elemento da lista\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os dados em treino e teste\n",
    "80% para treino e 20% para teste\n",
    "\n",
    "\n",
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split( # Separação dos dados para teste e treino\n",
    "    df_processed[\"strings\"], \n",
    "    df_processed[\"target\"], \n",
    "    test_size = 0.33, \n",
    "    random_state = 10\n",
    ")\n",
    "# Converte as strings para uma matriz de contagem dos tokens\n",
    "vect = CountVectorizer()\n",
    "vect.fit(df_processed[\"strings\"])\n",
    "\n",
    "dataset = { \n",
    "    \"X_train\": vect.transform(X_train),\n",
    "    \"X_test\": vect.transform(X_test),\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\" : y_test,\n",
    "    \"vect\": vect\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# um classificador linear que utiliza o Gradiente Descendente Estocástico como método de treino. \n",
    "# Por padrão, utiliza o estimador SVM.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# Uma rede neural Perceptron Multicamadas\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf_vectorize = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(dataset[\"X_train\"], dataset[\"y_train\"])\n",
    "\n",
    "products_model = {\n",
    "    \"clf\" : clf,\n",
    "    \"vect\": dataset[\"vect\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1389154     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.39548D+00    |proj g|=  4.96654D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    1    f=  1.36761D+00    |proj g|=  7.26860D-02\n",
      "\n",
      "At iterate    2    f=  1.31911D+00    |proj g|=  4.64021D-02\n",
      "\n",
      "At iterate    3    f=  1.22013D+00    |proj g|=  7.07583D-02\n",
      "\n",
      "At iterate    4    f=  1.06267D+00    |proj g|=  2.10391D-01\n",
      "\n",
      "At iterate    5    f=  7.40746D-01    |proj g|=  1.82635D-01\n",
      "\n",
      "At iterate    6    f=  5.75905D-01    |proj g|=  5.93391D-02\n",
      "\n",
      "At iterate    7    f=  4.41545D-01    |proj g|=  2.48162D-01\n",
      "\n",
      "At iterate    8    f=  3.82609D-01    |proj g|=  3.43705D-01\n",
      "\n",
      "At iterate    9    f=  3.09556D-01    |proj g|=  7.49817D-02\n",
      "\n",
      "At iterate   10    f=  2.85312D-01    |proj g|=  8.38132D-02\n",
      "\n",
      "At iterate   11    f=  2.70587D-01    |proj g|=  3.39439D-02\n",
      "\n",
      "At iterate   12    f=  2.62130D-01    |proj g|=  2.39996D-02\n",
      "\n",
      "At iterate   13    f=  2.45541D-01    |proj g|=  9.67343D-02\n",
      "\n",
      "At iterate   14    f=  2.22563D-01    |proj g|=  5.98253D-02\n",
      "\n",
      "At iterate   15    f=  1.68262D-01    |proj g|=  2.20244D-02\n",
      "\n",
      "At iterate   16    f=  1.30864D-01    |proj g|=  4.22603D-02\n",
      "\n",
      "At iterate   17    f=  9.10418D-02    |proj g|=  2.86213D-02\n",
      "\n",
      "At iterate   18    f=  7.12259D-02    |proj g|=  5.46795D-02\n",
      "\n",
      "At iterate   19    f=  5.96538D-02    |proj g|=  3.50414D-02\n",
      "\n",
      "At iterate   20    f=  5.33593D-02    |proj g|=  1.50303D-02\n",
      "\n",
      "At iterate   21    f=  4.81842D-02    |proj g|=  1.54204D-02\n",
      "\n",
      "At iterate   22    f=  4.34231D-02    |proj g|=  1.33849D-02\n",
      "\n",
      "At iterate   23    f=  4.02375D-02    |proj g|=  9.35275D-03\n",
      "\n",
      "At iterate   24    f=  3.28389D-02    |proj g|=  1.07495D-02\n",
      "\n",
      "At iterate   25    f=  2.37012D-02    |proj g|=  1.46891D-02\n",
      "\n",
      "At iterate   26    f=  1.77869D-02    |proj g|=  4.11051D-02\n",
      "\n",
      "At iterate   27    f=  1.05766D-02    |proj g|=  1.62331D-02\n",
      "\n",
      "At iterate   28    f=  8.13871D-03    |proj g|=  7.60725D-03\n",
      "\n",
      "At iterate   29    f=  5.04336D-03    |proj g|=  3.98320D-03\n",
      "\n",
      "At iterate   30    f=  2.40834D-03    |proj g|=  5.09864D-03\n",
      "\n",
      "At iterate   31    f=  2.35242D-03    |proj g|=  1.48359D-02\n",
      "\n",
      "At iterate   32    f=  9.99328D-05    |proj g|=  1.15229D-03\n",
      "\n",
      "At iterate   33    f=  7.85854D-05    |proj g|=  7.28411D-04\n",
      "\n",
      "At iterate   34    f=  5.62501D-05    |proj g|=  2.80646D-04\n",
      "\n",
      "At iterate   35    f=  4.69883D-05    |proj g|=  1.89777D-04\n",
      "\n",
      "At iterate   36    f=  4.09405D-05    |proj g|=  1.23419D-04\n",
      "\n",
      "At iterate   37    f=  3.39757D-05    |proj g|=  6.61155D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     37     39      1     0     0   6.612D-05   3.398D-05\n",
      "  F =   3.3975739208873569E-005\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(70,), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(70,), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(70,), random_state=1,\n",
       "              solver='lbfgs', verbose=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "clf.fit(X_train_tfidf_vectorize, y_train) # Treino do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão do multinomialNB: \n",
      "0.9710467706013363\n",
      "Precisão do multinomialNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   maquiagem       0.98      0.99      0.98       348\n",
      "       livro       0.99      0.97      0.98       355\n",
      "        game       0.98      0.98      0.98       341\n",
      "   brinquedo       0.98      1.00      0.99       303\n",
      "\n",
      "    accuracy                           0.98      1347\n",
      "   macro avg       0.98      0.98      0.98      1347\n",
      "weighted avg       0.98      0.98      0.98      1347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "# Multinomial NB\n",
    "y_prediction = products_model[\"clf\"].predict(dataset[\"X_test\"])\n",
    "accuracy = accuracy_score(y_prediction, dataset[\"y_test\"])\n",
    "\n",
    "print (\"Precisão do multinomialNB: \")\n",
    "print (accuracy)\n",
    "\n",
    "products_metrics = accuracy\n",
    "\n",
    "\n",
    "# MPL Classifier\n",
    "vect_transform = vectorizer.transform(X_test)\n",
    "predicted = clf.predict(vect_transform)\n",
    "\n",
    "print (\"Precisão do multinomialNB: \")\n",
    "print(metrics.classification_report(y_test, predicted,target_names=y_test.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = [\"sombra\"]\n",
    "input_message = products_model[\"vect\"].transform(input_message)\n",
    "final_prediction = products_model[\"clf\"].predict(input_message)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: maquiagem\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted value: \" + final_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
