{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import regex\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import seaborn as sns\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed-metacritics-total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['denis', 'villeneuve', 'shows', 'us', 'all', ...</td>\n",
       "      <td>OCT 3, 2022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['amy', 'adams', 'gives', 'a', 'superb', 'perf...</td>\n",
       "      <td>MAR 7, 2022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['this', 'movie', 'is', 'not', 'for', 'everyon...</td>\n",
       "      <td>DEC 6, 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['arrival', 'is', 'one', 'of', 'my', 'favorite...</td>\n",
       "      <td>APR 3, 2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['i', 'do', 'not', 'think', 'this', 'movie', '...</td>\n",
       "      <td>MAR 2, 2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie name                                             Review   Created at  \\\n",
       "0    Arrival  ['denis', 'villeneuve', 'shows', 'us', 'all', ...  OCT 3, 2022   \n",
       "1    Arrival  ['amy', 'adams', 'gives', 'a', 'superb', 'perf...  MAR 7, 2022   \n",
       "2    Arrival  ['this', 'movie', 'is', 'not', 'for', 'everyon...  DEC 6, 2019   \n",
       "3    Arrival  ['arrival', 'is', 'one', 'of', 'my', 'favorite...  APR 3, 2020   \n",
       "4    Arrival  ['i', 'do', 'not', 'think', 'this', 'movie', '...  MAR 2, 2020   \n",
       "\n",
       "   Score    Genre  \n",
       "0    1.0  Mistery  \n",
       "1    1.0  Mistery  \n",
       "2    1.0  Mistery  \n",
       "3    1.0  Mistery  \n",
       "4    1.0  Mistery  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Created at</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['denis', 'villeneuve', 'shows', 'us', 'all', ...</td>\n",
       "      <td>OCT 3, 2022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['amy', 'adams', 'gives', 'a', 'superb', 'perf...</td>\n",
       "      <td>MAR 7, 2022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['this', 'movie', 'is', 'not', 'for', 'everyon...</td>\n",
       "      <td>DEC 6, 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['arrival', 'is', 'one', 'of', 'my', 'favorite...</td>\n",
       "      <td>APR 3, 2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>['i', 'do', 'not', 'think', 'this', 'movie', '...</td>\n",
       "      <td>MAR 2, 2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mistery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Movie name                                             Review   Created at  \\\n",
       "0    Arrival  ['denis', 'villeneuve', 'shows', 'us', 'all', ...  OCT 3, 2022   \n",
       "1    Arrival  ['amy', 'adams', 'gives', 'a', 'superb', 'perf...  MAR 7, 2022   \n",
       "2    Arrival  ['this', 'movie', 'is', 'not', 'for', 'everyon...  DEC 6, 2019   \n",
       "3    Arrival  ['arrival', 'is', 'one', 'of', 'my', 'favorite...  APR 3, 2020   \n",
       "4    Arrival  ['i', 'do', 'not', 'think', 'this', 'movie', '...  MAR 2, 2020   \n",
       "\n",
       "   Score    Genre  \n",
       "0    1.0  Mistery  \n",
       "1    1.0  Mistery  \n",
       "2    1.0  Mistery  \n",
       "3    1.0  Mistery  \n",
       "4    1.0  Mistery  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('stemmed', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (4536,) (4536,)\n",
      "Test data:  (1944,) (1944,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Review\"],\n",
    "                                                    df[\"Score\"],\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify=df[\"Score\"])\n",
    "print('Train data: ', X_train.shape, y_train.shape)\n",
    "print('Test data: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_bow shape:  (4536, 20559)\n",
      "X_test_bow shape:  (1944, 20559) \n",
      "\n",
      "Média do dataset de treino antes do standardization:  0.0049041224580728855\n",
      "Média após: 0.03206966833266205 \n",
      "\n",
      "Média do dataset de teste antes do standardization:  0.004652673816219386\n",
      "Média após: 0.02416135389039293\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words\n",
    "count_vect = CountVectorizer()  # Convercao das strings para uma matriz de contagem dos tokens\n",
    "\n",
    "# Tranformacao das string em uma matriz de string-termo (strings e termos das strings)\n",
    "# Extracao da contagem de tokens das strings usando o vocabulario anterior\n",
    "X_train_bow = count_vect.fit_transform(X_train)\n",
    "X_test_bow = count_vect.transform(X_test)\n",
    "\n",
    "print(\"X_train_bow shape: \",X_train_bow.shape)\n",
    "print(\"X_test_bow shape: \",X_test_bow.shape,\"\\n\")\n",
    "\n",
    "\n",
    "inst_scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "print(\"Média do dataset de treino antes do standardization: \",X_train_bow.mean())\n",
    "X_train_bow = inst_scaler.fit_transform(X_train_bow)\n",
    "print(\"Média após:\",X_train_bow.mean(),\"\\n\")\n",
    "\n",
    "inst_scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "print(\"Média do dataset de teste antes do standardization: \",X_test_bow.mean())\n",
    "X_test_bow = inst_scaler.fit_transform(X_test_bow)\n",
    "print(\"Média após:\",X_test_bow.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.83      0.27      0.41       648\n",
      "         0.0       0.48      0.22      0.30       648\n",
      "         1.0       0.40      0.88      0.55       648\n",
      "\n",
      "    accuracy                           0.46      1944\n",
      "   macro avg       0.57      0.46      0.42      1944\n",
      "weighted avg       0.57      0.46      0.42      1944\n",
      "\n",
      "Naive Bayes Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.48      0.49      0.48       648\n",
      "         0.0       0.39      0.32      0.35       648\n",
      "         1.0       0.47      0.54      0.50       648\n",
      "\n",
      "    accuracy                           0.45      1944\n",
      "   macro avg       0.45      0.45      0.45      1944\n",
      "weighted avg       0.45      0.45      0.45      1944\n",
      "\n",
      "Random Forest Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.66      0.60      0.63       648\n",
      "         0.0       0.49      0.53      0.51       648\n",
      "         1.0       0.61      0.62      0.62       648\n",
      "\n",
      "    accuracy                           0.58      1944\n",
      "   macro avg       0.59      0.58      0.59      1944\n",
      "weighted avg       0.59      0.58      0.59      1944\n",
      "\n",
      "KNN Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.26      0.34       648\n",
      "         0.0       0.37      0.07      0.12       648\n",
      "         1.0       0.38      0.86      0.52       648\n",
      "\n",
      "    accuracy                           0.40      1944\n",
      "   macro avg       0.41      0.40      0.33      1944\n",
      "weighted avg       0.41      0.40      0.33      1944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset (for example, the df_analise dataset)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train_bow, y_train)\n",
    "svm_predictions = svm_clf.predict(X_test_bow)\n",
    "print(\"SVM Accuracy:\", classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train_bow.toarray(), y_train)\n",
    "nb_predictions = nb_clf.predict(X_test_bow.toarray())\n",
    "print(\"Naive Bayes Accuracy:\", classification_report(y_test, nb_predictions))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_bow, y_train)\n",
    "rf_predictions = rf_clf.predict(X_test_bow)\n",
    "print(\"Random Forest Accuracy:\", classification_report(y_test, rf_predictions))\n",
    "\n",
    "# KNN Classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_bow, y_train)\n",
    "knn_predictions = knn_clf.predict(X_test_bow)\n",
    "print(\"KNN Accuracy:\", classification_report(y_test, knn_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
